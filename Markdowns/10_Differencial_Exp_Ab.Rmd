---
title: "Introduction to single-cell RNA-seq analysis"
date: "Sept 2022"
subtitle: Differencial Expression and Abundance
output:
  html_document:
    toc: yes
    number_sections: true
    code_folding: show 
---
```{r setup, echo=FALSE, include=FALSE, message=FALSE, purl=FALSE}
library(scater)
library(scran)
library(batchelor)
library(edgeR)
library(tidyverse)
library(patchwork)
library(DT)
library(bluster)
library(BiocParallel)
library(miloR)

knitr::opts_chunk$set(error=FALSE, 
                      message=FALSE, 
                      warning=FALSE, 
                      cache=TRUE, 
                      purl=TRUE)
set.seed(123)
```


Acknowledgments: much of the material in this section has been derived from the 
chapters on differential expression and abundance in the
[OSCA book](http://bioconductor.org/books/3.14/OSCA.basic/normalization.html) 
and the [Hemberg Group course materials](https://www.singlecellcourse.org/). Additional material concerning `miloR` has been based on the [demonstration from the Marioni Lab.](https://marionilab.github.io/miloR/articles/milo_gastrulation.html)

# Differential expression and abundance between conditions 



## Motivation

A powerful use of scRNA-seq technology lies in the design of replicated multi-condition experiments to detect changes in composition or expression between conditions. This can provide more biological insight than conventional scRNA-seq experiments involving only one biological condition, especially if we can relate population changes to specific biological states.

Differential analyses of multi-condition scRNA-seq experiments can be broadly split into two categories - differential expression (DE) and differential abundance (DA) analyses. The former tests for changes in expression between conditions for cells of the same 'type' that are present in both conditions, while the latter tests for changes in the composition of cell types (or states, etc.) between conditions.

## Setup

```{r load_packages, eval=FALSE}
library(scater)
library(scran)
library(batchelor)
library(edgeR)
library(tidyverse)
library(patchwork)
library(DT)
library(bluster)
library(BiocParallel)
library(miloR)

bpp <- MulticoreParam(7)
```

## Setting up the data

Due to the nature of differencial analysis we cannot use the downsampled version of the dataset for the this section so we have the full Caron dataset. We will start with just the PBMMC and ETV6-RUNX1 samples. It has been QCed, normalised and batch corrected as shown last week and clustered as shown this morning. We have selected the Leiden clustering with k=60 to go forward.

Load the SCE object:

```{r read_data, cache=FALSE}

sce <- readRDS("R_objects/Caron_clustered.PBMMCandETV6RUNX1.rds")

rownames(sce) <- uniquifyFeatureNames(rownames(sce), rowData(sce)$Symbol)

sce
```

We can plot any of the outputs of the dimensionality reduction in the reduced dimensions slot of the single cell object. 

```{r plot_TSNE_1}

plotReducedDim(sce, dimred = "TSNE_corrected", colour_by = "label")

```


## Differential expression between conditions

### Creating pseudo-bulk samples

The most obvious differential analysis is to look for changes in expression between conditions. We perform the DE analysis separately for each label. The actual DE testing is performed on “pseudo-bulk” expression profiles (Tung et al. 2017), generated by summing counts together for all cells with the same combination of label and sample. This leverages the resolution offered by single-cell technologies to define the labels, and combines it with the statistical rigor of existing methods for DE analyses involving a small number of samples.

Here we use `label` and `SampleName` as the parameter to aggregate by. This means for each true sample there will be a pseudo-sample for each of our defined clusters. We therefore would have a maximum of 7x17 (119) pseudo-samples. We will have less than this as there will be a few clusters with no cells from a particular sample.

```{r aggregate_cells}

summed <- aggregateAcrossCells(sce, 
                               id=colData(sce)[,c("label", "SampleName")])
summed
```

At this point, it is worth reflecting on the motivations behind the use of pseudo-bulking:

Larger counts are more amenable to standard DE analysis pipelines designed for bulk RNA-seq data. Normalization is more straightforward and certain statistical approximations are more accurate e.g., the saddlepoint approximation for quasi-likelihood methods or normality for linear models.
Collapsing cells into samples reflects the fact that our biological replication occurs at the sample level (Lun and Marioni 2017). Each sample is represented no more than once for each condition, avoiding problems from unmodelled correlations between samples. Supplying the per-cell counts directly to a DE analysis pipeline would imply that each cell is an independent biological replicate, which is not true from an experimental perspective. (A mixed effects model can handle this variance structure but involves extra statistical and computational complexity for little benefit, see Crowell et al. (2019).)
Variance between cells within each sample is masked, provided it does not affect variance across (replicate) samples. This avoids penalizing DEGs that are not uniformly up- or down-regulated for all cells in all samples of one condition. Masking is generally desirable as DEGs - unlike marker genes - do not need to have low within-sample variance to be interesting, e.g., if the treatment effect is consistent across replicate populations but heterogeneous on a per-cell basis. (Of course, high per-cell variability will still result in weaker DE if it affects the variability across populations, while homogeneous per-cell responses will result in stronger DE due to a larger population-level log-fold change. These effects are also largely desirable.)

### Performing the DE analysis

#### Introduction

The DE analysis will be performed using quasi-likelihood (QL) methods from the `edgeR` package (Robinson, McCarthy, and Smyth 2010; Chen, Lun, and Smyth 2016). This uses a negative binomial generalized linear model (NB GLM) to handle overdispersed count data in experiments with limited replication. In our case, we have biological variation with few replicates per sample group, so `edgeR` (or its contemporaries) is a natural choice for the analysis. You can read more about the `edgeR` package and how each step is being calculated here: (edgeR user guide)[https://bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf]

It is possible to use `DESeq2` here instead, the OSCA book uses `edgeR` so we have stuck to that but it is up to you.

We do not use all labels for GLM fitting as the strong DE between labels makes it difficult to compute a sensible average abundance to model the mean-dispersion trend. Moreover, label-specific batch effects would not be easily handled with a single additive term in the design matrix for the batch. Instead, we picked one of the labels to use for this demonstration.

```{r choose_cluster_and_subset}

current <- summed[,summed$label == "1"]

colData(current)

```

In order to use edgeR we must have the data stored in a `DGEList` object. For this we need our counts matrix and a data frame containing metadata on our pseudo-samples.

```{r make_edgeR_object}

countsToUse <- counts(current)
colnames(countsToUse) <- colData(current)$SampleName

y <- DGEList(countsToUse, samples=colData(current))
y

```

#### Pre-processing

A typical step in bulk RNA-seq data analyses is to remove samples with very low library sizes due to failed library preparation or sequencing. The very low counts in these samples can be troublesome in downstream steps such as normalization or for some statistical approximations used in the DE analysis. In our situation, this is equivalent to removing label-sample combinations that have very few or lowly-sequenced cells. The exact definition of “very low” will vary, but in this case, we remove combinations containing fewer than 20 cells (Crowell et al. 2019).

```{r discard_low_cells}
discarded <- current$ncells < 20
y <- y[,!discarded]
summary(discarded)
```

Another typical step in bulk RNA-seq analyses is to remove genes that are lowly expressed. This reduces computational work, improves the accuracy of mean-variance trend modelling and decreases the severity of the multiple testing correction. Genes are discarded if they are not expressed above a log-CPM threshold in a minimum number of samples (determined from the size of the smallest treatment group in the experimental design). The `filterByExpr` function keeps rows that have 'worthwhile' counts in a minimum number of samples In this case the minimum number would be 3 as that is the smallest SampleGroup size.

```{r remove_low_genes}

keep <- filterByExpr(y, group=current$SampleGroup)
y <- y[keep,]
summary(keep)

```

Finally, we correct for composition biases by computing normalization factors with the trimmed mean of M-values method (Robinson and Oshlack 2010). Counts for our pseudo-bulk samples are large enough to apply bulk normalization methods. In the case of single cell data this is helping to account for the differing numbers of cell counts that have been summed to produce the pseudo-samples.

```{r calc_norm_factors}

y <- calcNormFactors(y)
y$samples

```


As part of the usual diagnostics for a bulk RNA-seq DE analysis, we generate a mean-difference (MD) plot for each normalized pseudo-bulk profile. This should exhibit a trumpet shape centered at zero indicating that the normalization successfully removed systematic bias between profiles. Lack of zero-centering or dominant discrete patterns at low abundances may be symptomatic of deeper problems with normalization, possibly due to insufficient cells/reads/UMIs composing a particular pseudo-bulk profile.

```{r plot_MD}
par(mfrow=c(2,4))
for (i in seq_len(ncol(y))) {
    plotMD(y, column=i)
}
```


We also generate a multi-dimensional scaling (MDS) plot for the pseudo-bulk profiles. 
MDS arranges the points on the plot so that the distances among each pair of points 
correlates as best as possible to the dissimilarity between those two samples. The 
values on the two axes tell you nothing about the variables for a given sample - the 
plot is just a two dimensional space to arrange the points. You can think of this in a 
similar way to how you would read a PCA plot in bulk RNASeq as it allows us to visualize 
the structure of the data. The aim is to check whether samples separate by our known 
factors of interest. Strong separation foreshadows a large number of DEGs in the 
subsequent analysis.

```{r plot_MDS}
y$samples$SampleGroup <- factor(y$samples$SampleGroup)
limma::plotMDS(cpm(y, log=TRUE), col = as.numeric(y$samples$SampleGroup))
```

#### Statistical modelling

Our aim is to test whether the log-fold change between sample groups is significantly different from zero.

```{r design_model}
design <- model.matrix(~factor(SampleGroup), y$samples)
design
```

We estimate the negative binomial (NB) dispersions with estimateDisp(). The role of the NB dispersion is to model the mean-variance trend, which is not easily accommodated by QL dispersions alone due to the quadratic nature of the NB mean-variance trend.

```{r estimate_dispersions}
y <- estimateDisp(y, design)
```

When a negative binomial model is fitted, we need to estimate the BCV(s) before we carry out
the analysis. Biological coefficient of variation (BCV) for each gene as a function of the average abundance. The BCV is computed as the square root of the NB dispersion after empirical Bayes shrinkage towards the trend.  Hence, it is equivalent to estimating the dispersion(s) of the negative binomial model. Trended and common BCV estimates are shown in blue and red, respectively. 

```{r plot_BCV}
plotBCV(y)
```

We also estimate the quasi-likelihood dispersions with glmQLFit() (Chen, Lun, and Smyth 2016). This fits a GLM to the counts for each gene and estimates the QL dispersion from the GLM deviance. We set robust=TRUE to avoid distortions from highly variable clusters (Phipson et al. 2016). The QL dispersion models the uncertainty and variability of the per-gene variance - which is not well handled by the NB dispersions, so the two dispersion types complement each other in the final analysis.

```{r fit_QL}
fit <- glmQLFit(y, design, robust=TRUE)
```

QL dispersion estimates for each gene as a function of abundance. Raw estimates (black) are shrunk towards the trend (blue) to yield squeezed estimates (red).

```{r plot_QL_dispersion}
plotQLDisp(fit)
```

We test for differences in expression due to sample group using glmQLFTest(). The QLF-test is preferred to a likelihood ratio test as it reflects the uncertainty in estimating the dispersion for each gene. DEGs are defined as those with non-zero log-fold changes at a false discovery rate of 5%. If very few genes are significantly DE that sample group has little effect on the transcriptome.

The `coef` argument specifies which contrast you want tested. It is the number of the column in the model matrix. For us since we only have 2 columns in our model matrix (the intercept and PBMMC vs ETV6-RUNX1) we can specify this as "2".

```{r perform_DEA}
results <- glmQLFTest(fit, coef = 2)
summary(decideTests(results))
```

We can get the results of our comparison using the `topTags` function. By default this function will output the top 10 genes by FDR but you could change this using the `n =` argument.

```{r get_results}
topTags(results)
```

### Putting it all together

Now that we have laid out the theory underlying the DE analysis, we repeat this process for each of the labels. This is conveniently done using the `pseudoBulkDGE` function from `scran`, which will loop over all labels and apply the exact analysis described above to each label. To prepare for this, we filter out all sample-label combinations with insufficient cells.

```{r filter_summed_counts}
summed.filt <- summed[,summed$ncells >= 20]
```

We construct a common design matrix that will be used in the analysis for each label. Recall that this matrix should have one row per unique sample (and named as such), reflecting the fact that we are modelling counts on the sample level instead of the cell level.

```{r get_common_metadata}

targets <- colData(sce)[!duplicated(corrected$SampleName),] %>%
  data.frame()
```

```{r design_matrix_for_looping}

design <- model.matrix(~factor(SampleGroup), data=targets)
rownames(design) <- targets$SampleName
```

We then apply the `pseudoBulkDGE` function to obtain a list of DE genes for each label. This function puts some additional effort into automatically dealing with labels that are not represented in all sample groups, for which a DE analysis between conditions is meaningless; or are not represented in a sufficient number of replicate samples to enable modelling of biological variability.

```{r run_DEA_loop}
summed.filt$SampleGroup <- factor(summed.filt$SampleGroup)

de.results <- pseudoBulkDGE(summed.filt, 
    label = summed.filt$label,
    design = ~SampleGroup,
    coef = "SampleGroupPBMMC",
    condition = summed.filt$SampleName
)

de.results

de.results[[1]]
```

We examine the numbers of DEGs at a FDR of 5% for each label using the `decideTestsPerLabel` function. Note that genes listed as NA were either filtered out as low-abundance genes for a given label’s analysis, or the comparison of interest was not possible for a particular label, e.g., due to lack of residual degrees of freedom or an absence of samples from both conditions.

```{r per_label_DEGs}
is.de <- decideTestsPerLabel(de.results, threshold=0.05)
summarizeTestsPerLabel(is.de)
```


For each gene, we compute the percentage of labels in which that gene is upregulated or downregulated. (Here, we consider a gene to be non-DE if it is not retained after filtering.).


```{r upregulated_genes}

up.de <- is.de > 0 & !is.na(is.de)
head(sort(rowMeans(up.de), decreasing=TRUE), 10)
```

```{r downregulated_genes}

down.de <- is.de < 0 & !is.na(is.de)
head(sort(rowMeans(down.de), decreasing=TRUE), 10)
```

We further identify label-specific DE genes that are significant in our label of interest yet not DE in any other label. As hypothesis tests are not typically geared towards identifying genes that are not DE, we use an ad hoc approach where we consider a gene to be consistent with the null hypothesis for a label if it fails to be detected even at a generous FDR threshold of 50%.

```{r de_in_1_but_not_in_rest}
remotely.de <- decideTestsPerLabel(de.results, threshold=0.5)
not.de <- remotely.de==0 | is.na(remotely.de)

cx <- "1"

other.labels <- setdiff(colnames(not.de), cx)

unique.degs <- is.de[,cx]!=0 & rowMeans(not.de[,other.labels])==1
unique.degs <- names(which(unique.degs))
head(unique.degs)
```

Another thing we may be interested in is to inspect the top significantly differential expressed gene. To avoid an error caused by negative size factors and since we don't need them here we remove the size factors from the summed and filtered single cell object `summed.filt`.

```{r}
top_gene <- rownames(de.results[[1]][order(de.results[[1]]$FDR),])[1]

sizeFactors(summed.filt) <- NULL

plotExpression(logNormCounts(summed.filt), 
    features=top_gene,
    x="SampleName", colour_by="SampleName", 
    other_fields="label") + 
    facet_wrap(~label) +
  ggtitle(top_gene)
```


## Exercise 1

:::exercise

See the accompanying worksheet for this session, which includes the code below
for the exercise. We want to achieve the following:

- Rerun the differential expression analysis using the PRE-T and HHD samples.

- Determine which cluster has the most DEGs?

- Determine which genes are significantly DE in that cluster and not in any other?

```{r}
# First load in the other two sample groups
sce_PRET_HHD <- readRDS("R_objects/Caron_clustered.PRETandHHD.rds")

# replace the ensembl IDs with gene symbols where possible
rownames(sce_PRET_HHD) <- uniquifyFeatureNames(rownames(sce_PRET_HHD), rowData(sce_PRET_HHD)$Symbol)

# check your sce object
sce_PRET_HHD

# Part A
# 

```

<details><summary>Hint A</summary>

Look at the set.seed() function

</details>

<details><summary>Hint B</summary>

You can replace what we colour by with any of the gene names in our dataset as they are stored as the rownames in our object.

</details>

<details><summary>Hint C</summary>

The function facet_wrap() can be used to modify ggplots as we did earlier.

</details>

<details><summary>Hint D</summary>

You can replace values in the perplexity argument of the runTSNE() function.

</details>

<details><summary>Answer</summary>

Here is the complete script: 

```{r}
```

Some things to note from our data exploration: 

- Changing the random seed doesn't seem to _qualitatively_ change the results
dramatically. The same groups of cells are still seen. However, their relative
position on the axis might change from run to run.
- Low perplexities will favour resolution of finer structure, possibly to the
point that the visualization is compromised by random noise. Thus, it is
advisable to test different perplexity values to ensure that the choice of
perplexity does not drive the interpretation of the plot.
- Exploring the expression of known marker genes (from literature or previous
experiments we might have done) may help us interpret these plots and judge
whether a particular choice of perplexity is adequate to represent the expected
cell types in our data.

</details>

:::

### Differences between celltypes

The above example of differential expression focused on testing for differences in expression between conditions for the same cell type or label. However, the same methodology can be applied to test for differences between cell types across samples. This kind of DE analysis can overcome a lack of suitable replication.  

# Using a dummy value for the label to allow us to include multiple cell types
# in the fitted model; otherwise, each cell type will be processed separately.

```{r}
summed.sub <- summed[,summed$label %in% c("3", "4")]

between.res <- pseudoBulkDGE(summed.sub,
    label=rep("dummy", ncol(summed.sub)),
    design=~factor(SampleName) + factor(label),
    coef="factor(label)4")[[1]]

table(Sig=between.res$FDR <= 0.05, Sign=sign(between.res$logFC))

```

```{r}
between.res[order(between.res$PValue),]
```

```{r}
summed.sub <- logNormCounts(summed.sub, size.factors=NULL)
plotExpression(summed.sub, 
    features=head(rownames(between.res)[order(between.res$PValue)]),
    x="label", 
    colour_by=I(factor(summed.sub$SampleName)))
```

Whether or not this is a scientifically meaningful comparison depends on the nature of the labels. These particular labels were defined by clustering, which means that the presence of DEGs is a foregone conclusion. Nonetheless, it may have some utility for applications where the labels are defined using independent information, e.g., from FACS.


## Differential abundance between conditions

### Overview

In a DA analysis, we test for significant changes in per-label cell abundance across conditions. This will reveal which cell types are depleted or enriched upon treatment, which is arguably just as interesting as changes in expression within each cell type. The DA analysis has a long history in flow cytometry (Finak et al. 2014; Lun, Richard, and Marioni 2017) where it is routinely used to examine the effects of different conditions on the composition of complex cell populations. By performing it here, we effectively treat scRNA-seq as a “super-FACS” technology for defining relevant subpopulations using the entire transcriptome.

```{r}

plotReducedDim(sce, dimred = "TSNE_corrected", colour_by = "label")

```

Milo object, need to add PCA, extra slots for milo stuff.

```{r}
library(miloR)

milo <- Milo(sce)

milo
```

importance of K and D

```{r}

milo <- buildGraph(milo, k = 60, d = 30, reduced.dim = "corrected", BPPARAM = MulticoreParam(7))
```

importance of K and D
```{r}

milo <- makeNhoods(milo, prop = 0.1, k = 60, d=30, refined = TRUE)
```

Want peak to be greater than 5 x number of samples. Or between 50 and 100...

```{r}

plotNhoodSizeHist(milo)
```

```{r}

milo <- countCells(milo, meta.data = data.frame(colData(milo)), sample="SampleName")

head(nhoodCounts(milo))
```

```{r}

milo_design <- data.frame(colData(milo))[,c("SampleName", "SampleGroup")]
milo_design <- distinct(milo_design)
rownames(milo_design) <- milo_design$SampleName

milo_design
```
Importance of D and defaults here

```{r}

milo <- calcNhoodDistance(milo, d=30, reduced.dim = "corrected")
```

```{r}

da_results <- testNhoods(milo, design = ~ SampleGroup, design.df = milo_design)

da_results %>%
  arrange(SpatialFDR) %>%
  head()
```

```{r}

ggplot(da_results, aes(PValue)) + geom_histogram(bins=50)
```

Then we visualize the test results with a volcano plot (remember that each point here represents a neighbourhood, _not_ a cell).

```{r}
ggplot(da_results, aes(logFC, -log10(SpatialFDR))) + 
  geom_point() +
  geom_hline(yintercept = 1) ## Mark significance threshold (10% FDR)
```

```{r}
milo <- buildNhoodGraph(milo)

```

Has to be called UMAP. Explain plot.

```{r}
reducedDim(milo, "UMAP") <- reducedDim(milo, "UMAP_corrected")
milo

plotUMAP(milo, colour_by = "label", text_by = "label") + plotNhoodGraphDA(milo, da_results, alpha=0.05) +
  plot_layout(guides="collect")
```

Explain label fraction.

```{r}
da_results <- annotateNhoods(milo, da_results, coldata_col = "label")
head(da_results)
```

```{r}
ggplot(da_results, aes(label_fraction)) + geom_histogram(bins=50)
```

```{r}
da_results$label <- ifelse(da_results$label_fraction < 0.7, "Mixed", da_results$label)

da_results
```

```{r}
plotDAbeeswarm(da_results, group.by = "label")
```

### Grouping Neighbourhoods

```{r}
da_results <- groupNhoods(milo, da_results, max.lfc.delta = 10)
da_results
length(unique(da_results$NhoodGroup))
```

```{r}
plotNhoodGroups(milo, da_results, layout="UMAP") 
```

```{r}
plotDAbeeswarm(da_results, "NhoodGroup")

```

```{r}
# Exercise - play with delta value and overlap to get base grouping
```

```{r}
set.seed(42)
da_results <- groupNhoods(milo, da_results, max.lfc.delta = 5, overlap=5)
plotNhoodGroups(milo, da_results, layout="UMAP")
```

```{r}
plotDAbeeswarm(da_results, group.by = "NhoodGroup")
```

```{r}

```






## Session information

<details>
```{r}
sessionInfo()
```
</details>
